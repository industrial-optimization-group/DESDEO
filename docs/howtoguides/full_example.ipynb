{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# A full example: from problem definition to solutions using interactive multiobjective optimization methods\n",
    "In this example, we will see how we can define a simple problem and how to solve it using an interactive multiobjective optimization method.\n",
    "\n",
    "## Defining a multiobjective optimization problem\n",
    "As an example, consider the following multiobjective optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\min f_1(\\mathbf{x}) &= x_1^2 - c_1\\sin(x_2) \\\\\n",
    "\\min f_2(\\mathbf{x}) &= x_2^2 - \\cos(3x_1) \\\\\n",
    "\\text{s.t.}\\quad & g_1(\\mathbf{x}) = x_1 + x_2 \\leq 10, \\\\\n",
    "                 & -5 \\leq x_1 \\leq 5, \\\\\n",
    "                 & -5 \\leq x_2 \\leq 5, \\\\\n",
    "                 & c_1 = 1.5.\n",
    "\\end{align*}\n",
    "\n",
    "$$\n",
    "\n",
    "We see that we have two objective functions, $f_1$ and $f_2$, two decision variables, $\\mathbf{x} = (x_1$, $x_2),$ a constant, $c_1 = 2.5$, and a constraint $g_1$. The values of the decision variables are also bound\n",
    "to be between $-5$ and $5$.\n",
    "\n",
    "To begin, we will need to import relevant code from DESDEO first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are to just suppress warnings in the outputs of the example\n",
    "import warnings\n",
    "\n",
    "from desdeo.problem import Constant, Constraint, ConstraintTypeEnum, Objective, Problem, Variable, VariableTypeEnum\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Defining constants and variables\n",
    "Next, we will define the constants and variables. With constants and variables, the attribute `symbol` is very important, as it will be used later in function definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_x_1 = Variable(\n",
    "    name=\"The first variable, x_1\",\n",
    "    symbol=\"x_1\",\n",
    "    variable_type=VariableTypeEnum.real,\n",
    "    lowerbound=-5.0,\n",
    "    upperbound=5.0,\n",
    "    initial_value=1.0,\n",
    ")\n",
    "variable_x_2 = Variable(\n",
    "    name=\"The first variable, x_2\",\n",
    "    symbol=\"x_2\",\n",
    "    variable_type=VariableTypeEnum.real,\n",
    "    lowerbound=-5.0,\n",
    "    upperbound=5.0,\n",
    "    initial_value=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "We have defined the variables to be a real numbers by setting the attribute `variable_type=VariableTypeEnum.real`, and we have bound their values by setting the `lowerbound` and `upperbound` attributes. The `initial_value` of the variables have also been set. Notice that the `name` of the variable is only important in providing information about the variable.\n",
    "\n",
    "Similar to variables, we can define our constant $c_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_c_1 = Constant(name=\"The constant c_1\", symbol=\"c_1\", value=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "A constant has not bounds since its value, by definition, is not going to change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Defining constraints and objective functions\n",
    "We can now proceed to defining objective and constraint functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_f_1 = Objective(\n",
    "    name=\"Objective f_1\",\n",
    "    symbol=\"f_1\",\n",
    "    func=\"x_1**2 - c_1*Sin(x_2)\",\n",
    "    maximize=False,\n",
    "    is_convex=False,\n",
    "    is_linear=False,\n",
    "    is_twice_differentiable=True,\n",
    ")\n",
    "objective_f_2 = Objective(\n",
    "    name=\"Objective f_2\",\n",
    "    symbol=\"f_2\",\n",
    "    func=\"x_2**2 - Cos(3*x_1)\",\n",
    "    maximize=False,\n",
    "    is_convex=False,\n",
    "    is_linear=False,\n",
    "    is_twice_differentiable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Similar to variables and constants, we have a `name` and a `symbol` attribute. We now also have a `func` attribute, which is the mathematical representation of the objective function. Notice how we have utilized\n",
    "the symbols we defined earlier for the variables and constants in the `func` attribute. Since we are minimizing both objective functions, we have set `maximize=False`. Lastly, we have the attributes `is_linear`, `is_convex`,\n",
    "and `is_twice_differentiable`, which tell us whether the objective function is convex, linear, or differentiable, respectively. Since our objective functions are neither convex or linear, the first two of these attributes\n",
    "are set to `False`, while the last one is set to `True`, because the functions are (twice) differentiable in $x_1$ and $x_2$.\n",
    "\n",
    "Our constraint $g_1$ is defined similarly to objective functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_g_1 = Constraint(\n",
    "    name=\"Constraint g_1\",\n",
    "    symbol=\"g_1\",\n",
    "    func=\"x_1 + x_2 - 10\",\n",
    "    cons_type=ConstraintTypeEnum.LTE,\n",
    "    is_linear=True,\n",
    "    is_convex=True,\n",
    "    is_twice_differentiable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "One might notice that the `func` of the constraint is not exactly the same as in our problem definition. This is because in DESDEO, constraints are expected in a standard form, where inequality constraints $g$ and equality\n",
    "constraints $h$ are defines as $g \\leq 0$ and $h = 0$. We readily see that if we define $g_1 = x_1 + x_2 - 10$ it is now congruent with this standard form and equivalent to the original constraint in our problem. \n",
    "\n",
    "To express whether we are dealing with an equality or inequality constraint, we provide the attribute `const_type`, which we set to be `ConstraintTypeEnum.LTE` to express a constraint of type \"less than or equal\" (for an quality constraint, we would set the attribute to `ConstraintTypeEnum.EQ` instead.) The rest of the attributes are the same as found when defining an instance of `Objective`.\n",
    "\n",
    "## Putting it all together\n",
    "We can now define our multiobjective optimization problem as an instance of the `Problem` class, which is used to represent all kinds of multiobjective optimization problems in DESDEO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem(\n",
    "    name=\"Example problem\",\n",
    "    description=\"This problem is a simple example on how to define problems in DESDEO.\",\n",
    "    constants=[constant_c_1],\n",
    "    variables=[variable_x_1, variable_x_2],\n",
    "    objectives=[objective_f_1, objective_f_2],\n",
    "    constraints=[constraint_g_1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "And that is it! We are now ready to do all kinds of interesting things with our problem. We will begin by calculating its ideal point, and approximating its nadir point.\n",
    "\n",
    "## Ideal and nadir points\n",
    "Because the scalarization functions required by the interactive method we are going to apply require an ideal point and an approximation of the nadir point, we need to calculate them next. Luckily, this is very straightforward if we utilize the _payoff-table method_, which is well suited for the purpose of this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from desdeo.tools import payoff_table_method\n",
    "\n",
    "ideal, nadir = payoff_table_method(problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We can then update our problem with the new ideal and nadir point values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = problem.update_ideal_and_nadir(new_ideal=ideal, new_nadir=nadir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Solving the problem using the reference point method\n",
    "We are now ready to solve the problem utilizing an interactive multiobjective optimization method found in DESDEO. We will be utilizing the _reference point method_.\n",
    "\n",
    "Because the reference point method requires a _reference point_, it might be a good idea to inspect the ideal and nadir points we just calculated to get an idea of the ranges for the two objective functions $f_1$ and $f_2$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ideal values: {problem.get_ideal_point()}\")\n",
    "print(f\"Nadir values: {problem.get_nadir_point()} (approximations!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We can safely assume the nadir value for $f_1$ to be (very near) zero.\n",
    "\n",
    "Next, we can define an initial reference point and solve the problem using the reference point method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from desdeo.mcdm.reference_point_method import rpm_solve_solutions\n",
    "\n",
    "reference_point = {\"f_1\": -0.75, \"f_2\": 1.2}\n",
    "\n",
    "results = rpm_solve_solutions(problem, reference_point=reference_point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Let us then inspect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, result in enumerate(results):\n",
    "    print(f\"Solution {i + 1}:\")\n",
    "    print(f\"Objective function values \\t\\t {result.optimal_objectives}\")\n",
    "    print(f\"Decision variable values \\t\\t {result.optimal_variables}\")\n",
    "    print(f\"Constraint values \\t\\t\\t {result.constraint_values}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "We can readily inspect the objective function values and decision variable values in the results. We have three solutions, because the reference point method returns $k+1$ solutions, where $k$ is the number of objective functions. We also notice some new acquittances in the results, namely `_alpha`, `f_1_con`, and `f_2_con`. These are the symbols auxiliary variables and constraints that have been added to the problem automatically when it has been scalarized by the reference point method. These can be safely ignored for the purpose of this example.\n",
    "\n",
    "If we are not happy with the solutions, we can try to change the reference point. We can try to be more demanding (we are minimizing both objective functions, thus, less is more!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_point = {\"f_1\": -1.3, \"f_2\": -1.2}\n",
    "\n",
    "results = rpm_solve_solutions(problem, reference_point=reference_point)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Solution {i + 1}:\")\n",
    "    print(f\"Objective function values \\t\\t {result.optimal_objectives}\")\n",
    "    print(f\"Decision variable values \\t\\t {result.optimal_variables}\")\n",
    "    print(f\"Constraint values \\t\\t\\t {result.constraint_values}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, we got different results after changing the reference point. We can keep iterating the method by changing the reference point until we find something we are satisfied with (or the decision maker is!).\n",
    "\n",
    "Try changing the reference point again, or try modifying the problem! You can add a third objective functions, or you might come up with a completely new problem. The sky is the limit!\n",
    "\n",
    "## Conclusions\n",
    "In this example, we have seen how to define a multiobjective optimization problem, how to find out its nadir and (approximate) ideal points, and how to solve the problem utilizing the reference point method.\n",
    "\n",
    "DESDEO has support for many kinds of multiobjective optimization problems. Keep exploring the framework to find out what it has to offer!\n",
    "\n",
    "**Please note:** DESDEO 2.0 is still under heavy development. The documentation will be updated in due time with more examples like this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
